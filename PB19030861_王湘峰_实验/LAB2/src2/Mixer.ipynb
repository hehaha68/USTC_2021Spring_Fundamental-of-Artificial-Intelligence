{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "#禁止import除了torch以外的其他包，依赖这几个包已经可以完成实验了\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Mixer_Layer(nn.Module):\n",
    "    def __init__(self, patch_size, hidden_dim):\n",
    "        super(Mixer_Layer, self).__init__()\n",
    "        ########################################################################\n",
    "        #这里需要写Mixer_Layer（layernorm，mlp1，mlp2，skip_connection）\n",
    "        self.in_dim1 = (28//patch_size) ** 2\n",
    "        self.mlp1 = nn.Sequential(\n",
    "            nn.Linear(self.in_dim1,hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0),\n",
    "            nn.Linear(hidden_dim,self.in_dim1),\n",
    "            nn.Dropout(0)\n",
    "        )\n",
    "        self.mlp2 = nn.Sequential(\n",
    "            nn.Linear(14,hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0),\n",
    "            nn.Linear(hidden_dim,14),\n",
    "            nn.Dropout(0)            \n",
    "        )\n",
    "        \n",
    "        self.norm = nn.LayerNorm(14)\n",
    "        ########################################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        ########################################################################\n",
    "        x = self.norm(x)\n",
    "        x2 = self.mlp1(x.transpose(1,2)).transpose(1,2)\n",
    "        x = x + x2\n",
    "        x2 = self.norm(x)\n",
    "        x2 = self.mlp2(x2)\n",
    "        return x + x2\n",
    "        ########################################################################\n",
    "\n",
    "\n",
    "class MLPMixer(nn.Module):\n",
    "    def __init__(self, patch_size, hidden_dim, depth):\n",
    "        super(MLPMixer, self).__init__()\n",
    "        assert 28 % patch_size == 0, 'image_size must be divisible by patch_size'\n",
    "        assert depth > 1, 'depth must be larger than 1'\n",
    "        ########################################################################\n",
    "        #这里写Pre-patch Fully-connected, Global average pooling, fully connected\n",
    "        self.embed = nn.Conv2d(1,14,kernel_size = patch_size,stride = patch_size)\n",
    "        patch_num = (28//patch_size) ** 2\n",
    "        MIX = Mixer_Layer(patch_size,hidden_dim)\n",
    "        self.mixlayers = nn.Sequential(*[MIX for _ in range(depth)])\n",
    "        self.norm = nn.LayerNorm(14)\n",
    "        self.connect = nn.Linear(14,10)\n",
    "        ########################################################################\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        ########################################################################\n",
    "        #注意维度的变化\n",
    "        x = self.embed(data).flatten(2).transpose(1,2)\n",
    "        x = self.mixlayers(x)\n",
    "        x = self.norm(x)\n",
    "        x = torch.mean(x,dim = 1)\n",
    "        x = self.connect(x)\n",
    "        return x\n",
    "        ########################################################################\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, n_epochs, criterion):\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            ########################################################################\n",
    "            #计算loss并进行优化\n",
    "            optimizer.zero_grad()\n",
    "            pre = model(data)\n",
    "            out1 = nn.functional.one_hot(target,num_classes = 10)\n",
    "            loss = criterion(pre,target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            ########################################################################\n",
    "            if batch_idx % 100 == 0:\n",
    "                print('Train Epoch: {}/{} [{}/{}]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, n_epochs, batch_idx * len(data), len(train_loader.dataset), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    num_correct = 0 #correct的个数\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "        ########################################################################\n",
    "        #需要计算测试集的loss和accuracy\n",
    "            pre = model(data)\n",
    "            out1 = nn.functional.one_hot(target,num_classes = 10)\n",
    "            loss = criterion(pre,target)\n",
    "            test_loss += loss\n",
    "            a = pre.argmax(dim = 1).tolist()\n",
    "            b = target.tolist()\n",
    "            for i in range(len(a)):\n",
    "                if a[i] == b[i]:\n",
    "                    num_correct += 1\n",
    "        accuracy = num_correct / 10000\n",
    "        ########################################################################\n",
    "        print(\"Test set: Average loss: {:.4f}\\t Acc {:.2f}\".format(test_loss.item(), accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0/5 [0/60000]\tLoss: 2.317000\n",
      "Train Epoch: 0/5 [12800/60000]\tLoss: 2.225142\n",
      "Train Epoch: 0/5 [25600/60000]\tLoss: 2.124949\n",
      "Train Epoch: 0/5 [38400/60000]\tLoss: 1.954020\n",
      "Train Epoch: 0/5 [51200/60000]\tLoss: 1.681075\n",
      "Train Epoch: 1/5 [0/60000]\tLoss: 1.613096\n",
      "Train Epoch: 1/5 [12800/60000]\tLoss: 1.388618\n",
      "Train Epoch: 1/5 [25600/60000]\tLoss: 1.168979\n",
      "Train Epoch: 1/5 [38400/60000]\tLoss: 1.124088\n",
      "Train Epoch: 1/5 [51200/60000]\tLoss: 1.075164\n",
      "Train Epoch: 2/5 [0/60000]\tLoss: 0.951489\n",
      "Train Epoch: 2/5 [12800/60000]\tLoss: 0.839138\n",
      "Train Epoch: 2/5 [25600/60000]\tLoss: 0.962859\n",
      "Train Epoch: 2/5 [38400/60000]\tLoss: 0.920439\n",
      "Train Epoch: 2/5 [51200/60000]\tLoss: 0.694689\n",
      "Train Epoch: 3/5 [0/60000]\tLoss: 0.760935\n",
      "Train Epoch: 3/5 [12800/60000]\tLoss: 0.696404\n",
      "Train Epoch: 3/5 [25600/60000]\tLoss: 0.835476\n",
      "Train Epoch: 3/5 [38400/60000]\tLoss: 0.728805\n",
      "Train Epoch: 3/5 [51200/60000]\tLoss: 0.684918\n",
      "Train Epoch: 4/5 [0/60000]\tLoss: 0.525856\n",
      "Train Epoch: 4/5 [12800/60000]\tLoss: 0.554833\n",
      "Train Epoch: 4/5 [25600/60000]\tLoss: 0.446779\n",
      "Train Epoch: 4/5 [38400/60000]\tLoss: 0.557346\n",
      "Train Epoch: 4/5 [51200/60000]\tLoss: 0.563896\n",
      "Test set: Average loss: 36.6874\t Acc 0.87\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    n_epochs = 5\n",
    "    batch_size = 128\n",
    "    learning_rate = 1e-3\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "    trainset = MNIST(root = './data', train=True, download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "    testset = MNIST(root = './data', train=False, download=True, transform=transform)\n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    \n",
    "    ########################################################################\n",
    "    model = MLPMixer(patch_size = 7, hidden_dim = 64, depth = 4).to(device) # 参数自己设定，其中depth必须大于1\n",
    "    # 这里需要调用optimizer，criterion(交叉熵)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate,momentum=0.9)\n",
    "    \n",
    "    ########################################################################\n",
    "    \n",
    "    train(model, train_loader, optimizer, n_epochs, criterion)\n",
    "    test(model, test_loader, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
