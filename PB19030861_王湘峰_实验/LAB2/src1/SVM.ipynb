{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxopt #用于求解线性规划\n",
    "from process_data import load_and_process_data\n",
    "from evaluation import get_micro_F1,get_macro_F1,get_acc\n",
    "\n",
    "\n",
    "#根据指定类别main_class生成1/-1标签\n",
    "def svm_label(labels,main_class):\n",
    "    new_label=[]\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i]==main_class:\n",
    "            new_label.append(1)\n",
    "        else:\n",
    "            new_label.append(-1)\n",
    "    return np.array(new_label)\n",
    "\n",
    "# 实现线性回归\n",
    "class SupportVectorMachine:\n",
    "\n",
    "    '''参数初始化 \n",
    "    lr: 梯度更新的学习率\n",
    "    Lambda: L2范数的系数\n",
    "    epochs: 更新迭代的次数\n",
    "    '''\n",
    "    def __init__(self,kernel,C,Epsilon):\n",
    "        self.kernel=kernel\n",
    "        self.C = C\n",
    "        self.Epsilon=Epsilon\n",
    "\n",
    "    '''KERNEL用于计算两个样本x1,x2的核函数'''\n",
    "    def KERNEL(self, x1, x2, kernel='Gauss', d=2, sigma=1):\n",
    "        #d是多项式核的次数,sigma为Gauss核的参数\n",
    "        K = 0\n",
    "        if kernel == 'Gauss':\n",
    "            K = np.exp(-(np.sum((x1 - x2) ** 2)) / (2 * sigma ** 2))\n",
    "        elif kernel == 'Linear':\n",
    "            K = np.dot(x1,x2)\n",
    "        elif kernel == 'Poly':\n",
    "            K = np.dot(x1,x2) ** d\n",
    "        else:\n",
    "            print('No support for this kernel')\n",
    "        return K\n",
    "\n",
    "    '''\n",
    "    根据训练数据train_data,train_label（均为np数组）求解svm,并对test_data进行预测,返回预测分数，即svm使用符号函数sign之前的值\n",
    "    train_data的shape=(train_num,train_dim),train_label的shape=(train_num,) train_num为训练数据的数目，train_dim为样本维度\n",
    "    预测结果的数据类型应为np数组，shape=(test_num,1) test_num为测试数据的数目\n",
    "    '''\n",
    "    def fit(self,train_data,train_label,test_data):\n",
    "        #需要你实现的部分\n",
    "        train_num,features = train_data.shape\n",
    "        kernel = np.zeros((train_num,train_num))\n",
    "        if self.kernel == 'Linear':\n",
    "            kernel = train_data@train_data.T\n",
    "        else:\n",
    "            for i in range(train_num):\n",
    "                for j in range(train_num):\n",
    "                    kernel[i,j] = self.KERNEL(train_data[i,:],train_data[j,:],kernel=self.kernel)       \n",
    "        P = cvxopt.matrix(np.outer(train_label,train_label) * kernel)\n",
    "        q = cvxopt.matrix(np.ones(train_num) * -1)\n",
    "        A = cvxopt.matrix(train_label,(1,train_num),'d')\n",
    "        b = cvxopt.matrix(0.0)\n",
    "        if self.C is None:\n",
    "            G = cvxopt.matrix(np.diag(np.ones(train_num)*-1))\n",
    "            h = cvxopt.matrix(np.zeros(train_num))\n",
    "        else:\n",
    "            M1 = np.diag(np.ones(train_num) * -1)\n",
    "            M2 = np.identity(train_num)\n",
    "            G = cvxopt.matrix(np.vstack([M1, M2]))\n",
    "            M1 = np.zeros(train_num)\n",
    "            M2 = np.ones(train_num) * self.C\n",
    "            h = cvxopt.matrix(np.hstack([M1, M2]))\n",
    "\n",
    "        solve = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "        a = np.ravel(solve['x'])\n",
    "        sv = a > Epsilon     \n",
    "        index = np.arange(len(a))[sv]  \n",
    "        alpha = a[sv]\n",
    "        SV = train_data[sv]  \n",
    "        SV_label = train_label[sv]  \n",
    "        omega = np.zeros(features)\n",
    "        \n",
    "        B = 0\n",
    "        for n in range(len(alpha)):\n",
    "            B = B + SV_label[n]\n",
    "            B = B - np.sum(alpha*SV_label*kernel[index[n],sv])\n",
    "        B = B / len(alpha)\n",
    "            \n",
    "        if self.kernel == 'Linear':\n",
    "            for n in range(len(a)):\n",
    "                omega += a[n] * train_label[n] * train_data[n]\n",
    "            return (test_data@omega.T + B).reshape(-1,1)\n",
    "        elif self.kernel == 'Gauss' or self.kernel == 'Poly':\n",
    "            predict = np.zeros(len(test_data))\n",
    "            for i in range(len(test_data)):\n",
    "                y  = 0\n",
    "                #for al,label,sv in zip(alpha,SV_label,SV):\n",
    "                for al,label,sv in zip(a,train_label,train_data):\n",
    "                    y += al * label * self.KERNEL(test_data[i],sv,kernel=self.kernel)\n",
    "                predict[i] = y\n",
    "            return predict.reshape(-1,1)\n",
    "        else:\n",
    "            print('No support for this kernel')\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_num: 3554\n",
      "test_num: 983\n",
      "train_feature's shape:(3554, 8)\n",
      "test_feature's shape:(983, 8)\n"
     ]
    }
   ],
   "source": [
    "Train_data,Train_label,Test_data,Test_label=load_and_process_data()\n",
    "Train_label=[label[0] for label in Train_label]\n",
    "Test_label=[label[0] for label in Test_label]\n",
    "train_data=np.array(Train_data)\n",
    "test_data=np.array(Test_data)\n",
    "test_label=np.array(Test_label).reshape(-1,1)\n",
    "#类别个数\n",
    "num_class=len(set(Train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.4159e+03 -9.7614e+03  6e+04  3e+00  3e-13\n",
      " 1: -9.4986e+02 -6.5633e+03  1e+04  4e-01  3e-13\n",
      " 2: -9.0554e+02 -3.5160e+03  4e+03  1e-01  3e-13\n",
      " 3: -9.5053e+02 -1.6024e+03  8e+02  3e-02  3e-13\n",
      " 4: -1.0444e+03 -1.2923e+03  3e+02  8e-03  3e-13\n",
      " 5: -1.0729e+03 -1.2298e+03  2e+02  4e-03  3e-13\n",
      " 6: -1.0917e+03 -1.1902e+03  1e+02  2e-03  3e-13\n",
      " 7: -1.1024e+03 -1.1692e+03  7e+01  1e-03  2e-13\n",
      " 8: -1.1119e+03 -1.1517e+03  4e+01  7e-04  3e-13\n",
      " 9: -1.1162e+03 -1.1438e+03  3e+01  4e-04  3e-13\n",
      "10: -1.1203e+03 -1.1364e+03  2e+01  2e-04  3e-13\n",
      "11: -1.1227e+03 -1.1328e+03  1e+01  1e-04  3e-13\n",
      "12: -1.1246e+03 -1.1300e+03  6e+00  4e-05  3e-13\n",
      "13: -1.1261e+03 -1.1280e+03  2e+00  6e-06  3e-13\n",
      "14: -1.1266e+03 -1.1275e+03  9e-01  2e-06  3e-13\n",
      "15: -1.1270e+03 -1.1270e+03  5e-02  6e-09  3e-13\n",
      "16: -1.1270e+03 -1.1270e+03  2e-03  2e-10  3e-13\n",
      "17: -1.1270e+03 -1.1270e+03  4e-05  3e-12  3e-13\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.0380e+03 -1.0857e+04  5e+04  3e+00  6e-13\n",
      " 1: -2.0875e+03 -7.9495e+03  7e+03  1e-01  6e-13\n",
      " 2: -2.3734e+03 -3.2502e+03  9e+02  2e-02  5e-13\n",
      " 3: -2.5886e+03 -3.0175e+03  4e+02  7e-03  5e-13\n",
      " 4: -2.6536e+03 -2.9271e+03  3e+02  4e-03  5e-13\n",
      " 5: -2.6544e+03 -2.9264e+03  3e+02  4e-03  5e-13\n",
      " 6: -2.6618e+03 -2.9250e+03  3e+02  3e-03  5e-13\n",
      " 7: -2.6805e+03 -2.8981e+03  2e+02  2e-03  5e-13\n",
      " 8: -2.6816e+03 -2.8990e+03  2e+02  2e-03  5e-13\n",
      " 9: -2.7432e+03 -2.7953e+03  5e+01  4e-04  6e-13\n",
      "10: -2.7541e+03 -2.7802e+03  3e+01  1e-04  6e-13\n",
      "11: -2.7602e+03 -2.7715e+03  1e+01  4e-05  6e-13\n",
      "12: -2.7628e+03 -2.7681e+03  5e+00  2e-05  6e-13\n",
      "13: -2.7642e+03 -2.7662e+03  2e+00  5e-06  6e-13\n",
      "14: -2.7648e+03 -2.7655e+03  7e-01  1e-06  6e-13\n",
      "15: -2.7651e+03 -2.7652e+03  7e-02  6e-08  7e-13\n",
      "16: -2.7651e+03 -2.7651e+03  7e-03  6e-09  7e-13\n",
      "17: -2.7651e+03 -2.7651e+03  6e-04  4e-10  7e-13\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.2283e+03 -1.0144e+04  5e+04  3e+00  6e-13\n",
      " 1: -1.5021e+03 -7.1327e+03  8e+03  2e-01  6e-13\n",
      " 2: -1.5747e+03 -2.6575e+03  1e+03  3e-02  5e-13\n",
      " 3: -1.7590e+03 -2.2104e+03  5e+02  1e-02  5e-13\n",
      " 4: -1.8490e+03 -2.0498e+03  2e+02  3e-03  5e-13\n",
      " 5: -1.8550e+03 -2.0397e+03  2e+02  2e-03  5e-13\n",
      " 6: -1.8649e+03 -2.0232e+03  2e+02  2e-03  5e-13\n",
      " 7: -1.9015e+03 -1.9629e+03  6e+01  4e-04  6e-13\n",
      " 8: -1.9107e+03 -1.9486e+03  4e+01  1e-04  6e-13\n",
      " 9: -1.9125e+03 -1.9453e+03  3e+01  8e-05  5e-13\n",
      "10: -1.9211e+03 -1.9341e+03  1e+01  1e-05  6e-13\n",
      "11: -1.9252e+03 -1.9293e+03  4e+00  3e-06  6e-13\n",
      "12: -1.9267e+03 -1.9276e+03  9e-01  4e-07  6e-13\n",
      "13: -1.9271e+03 -1.9272e+03  9e-02  4e-08  7e-13\n",
      "14: -1.9271e+03 -1.9271e+03  4e-03  2e-09  7e-13\n",
      "15: -1.9271e+03 -1.9271e+03  4e-05  2e-11  7e-13\n",
      "Optimal solution found.\n",
      "Acc: 0.659206510681587\n",
      "0.7671840354767183\n",
      "0.5671641791044776\n",
      "0.6838046272493573\n",
      "macro-F1: 0.6727176139435177\n",
      "micro-F1: 0.659206510681587\n"
     ]
    }
   ],
   "source": [
    "#kernel为核函数类型，可能的类型有'Linear'/'Poly'/'Gauss'\n",
    "#C为软间隔参数；\n",
    "#Epsilon为拉格朗日乘子阈值，低于此阈值时将该乘子设置为0\n",
    "kernel='Linear' \n",
    "C = 1\n",
    "Epsilon=10e-5\n",
    "#生成SVM分类器\n",
    "SVM=SupportVectorMachine(kernel,C,Epsilon)\n",
    "predictions = []\n",
    "#one-vs-all方法训练num_class个二分类器\n",
    "for k in range(1,num_class+1):\n",
    "    #将第k类样本label置为1，其余类别置为-1\n",
    "    train_label=svm_label(Train_label,k)\n",
    "    # 训练模型，并得到测试集上的预测结果\n",
    "    prediction=SVM.fit(train_data,train_label,test_data)\n",
    "    predictions.append(prediction)\n",
    "predictions=np.array(predictions)\n",
    "#one-vs-all, 最终分类结果选择最大score对应的类别\n",
    "pred=np.argmax(predictions,axis=0)+1\n",
    "\n",
    "# 计算准确率Acc及多分类的F1-score\n",
    "print(\"Acc: \"+str(get_acc(test_label,pred)))\n",
    "print(\"macro-F1: \"+str(get_macro_F1(test_label,pred)))\n",
    "print(\"micro-F1: \"+str(get_micro_F1(test_label,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.2803e+03 -8.7706e+03  5e+04  3e+00  3e-14\n",
      " 1: -8.4676e+02 -5.4384e+03  7e+03  2e-01  3e-14\n",
      " 2: -8.6401e+02 -1.5645e+03  8e+02  2e-02  2e-14\n",
      " 3: -9.3835e+02 -1.3074e+03  4e+02  8e-03  2e-14\n",
      " 4: -9.8443e+02 -1.1481e+03  2e+02  3e-03  2e-14\n",
      " 5: -9.8781e+02 -1.1399e+03  2e+02  3e-03  2e-14\n",
      " 6: -9.9845e+02 -1.1095e+03  1e+02  2e-03  2e-14\n",
      " 7: -1.0076e+03 -1.0845e+03  8e+01  9e-04  2e-14\n",
      " 8: -1.0143e+03 -1.0662e+03  5e+01  3e-04  2e-14\n",
      " 9: -1.0183e+03 -1.0561e+03  4e+01  2e-04  2e-14\n",
      "10: -1.0229e+03 -1.0436e+03  2e+01  1e-14  3e-14\n",
      "11: -1.0260e+03 -1.0374e+03  1e+01  4e-15  2e-14\n",
      "12: -1.0270e+03 -1.0353e+03  8e+00  2e-14  2e-14\n",
      "13: -1.0281e+03 -1.0332e+03  5e+00  1e-14  2e-14\n",
      "14: -1.0289e+03 -1.0318e+03  3e+00  4e-14  2e-14\n",
      "15: -1.0295e+03 -1.0308e+03  1e+00  5e-14  3e-14\n",
      "16: -1.0297e+03 -1.0306e+03  9e-01  3e-14  2e-14\n",
      "17: -1.0297e+03 -1.0306e+03  9e-01  1e-13  2e-14\n",
      "18: -1.0299e+03 -1.0304e+03  5e-01  3e-14  2e-14\n",
      "19: -1.0299e+03 -1.0303e+03  4e-01  7e-14  2e-14\n",
      "20: -1.0300e+03 -1.0303e+03  3e-01  3e-14  2e-14\n",
      "21: -1.0300e+03 -1.0302e+03  2e-01  1e-13  2e-14\n",
      "22: -1.0301e+03 -1.0302e+03  9e-02  1e-13  2e-14\n",
      "23: -1.0301e+03 -1.0301e+03  2e-02  4e-14  3e-14\n",
      "24: -1.0301e+03 -1.0301e+03  4e-04  5e-14  3e-14\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.8738e+03 -9.7540e+03  4e+04  3e+00  5e-14\n",
      " 1: -2.0413e+03 -6.9428e+03  6e+03  2e-01  5e-14\n",
      " 2: -2.2639e+03 -3.0593e+03  9e+02  2e-02  5e-14\n",
      " 3: -2.4639e+03 -2.8447e+03  4e+02  9e-03  5e-14\n",
      " 4: -2.5666e+03 -2.7367e+03  2e+02  3e-03  5e-14\n",
      " 5: -2.6092e+03 -2.6870e+03  8e+01  1e-03  5e-14\n",
      " 6: -2.6244e+03 -2.6697e+03  5e+01  5e-04  5e-14\n",
      " 7: -2.6354e+03 -2.6570e+03  2e+01  2e-04  5e-14\n",
      " 8: -2.6421e+03 -2.6493e+03  7e+00  6e-05  5e-14\n",
      " 9: -2.6443e+03 -2.6469e+03  3e+00  1e-05  6e-14\n",
      "10: -2.6453e+03 -2.6458e+03  6e-01  8e-07  6e-14\n",
      "11: -2.6455e+03 -2.6456e+03  6e-02  7e-08  6e-14\n",
      "12: -2.6455e+03 -2.6455e+03  1e-03  5e-10  6e-14\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.1684e+03 -9.2723e+03  4e+04  3e+00  6e-14\n",
      " 1: -1.4956e+03 -6.2132e+03  6e+03  1e-01  6e-14\n",
      " 2: -1.6217e+03 -2.4259e+03  9e+02  2e-02  5e-14\n",
      " 3: -1.7787e+03 -2.0679e+03  3e+02  5e-03  5e-14\n",
      " 4: -1.8099e+03 -2.0096e+03  2e+02  3e-03  5e-14\n",
      " 5: -1.8368e+03 -1.9541e+03  1e+02  1e-03  5e-14\n",
      " 6: -1.8566e+03 -1.9127e+03  6e+01  1e-04  6e-14\n",
      " 7: -1.8612e+03 -1.9039e+03  4e+01  1e-04  5e-14\n",
      " 8: -1.8682e+03 -1.8906e+03  2e+01  4e-05  5e-14\n",
      " 9: -1.8710e+03 -1.8858e+03  1e+01  2e-05  5e-14\n",
      "10: -1.8737e+03 -1.8814e+03  8e+00  1e-05  5e-14\n",
      "11: -1.8750e+03 -1.8794e+03  4e+00  4e-06  5e-14\n",
      "12: -1.8757e+03 -1.8783e+03  3e+00  6e-07  6e-14\n",
      "13: -1.8760e+03 -1.8779e+03  2e+00  3e-07  5e-14\n",
      "14: -1.8763e+03 -1.8776e+03  1e+00  2e-07  5e-14\n",
      "15: -1.8765e+03 -1.8774e+03  9e-01  1e-07  5e-14\n",
      "16: -1.8767e+03 -1.8772e+03  5e-01  3e-08  5e-14\n",
      "17: -1.8768e+03 -1.8771e+03  3e-01  1e-08  5e-14\n",
      "18: -1.8769e+03 -1.8769e+03  1e-01  1e-09  6e-14\n",
      "19: -1.8769e+03 -1.8769e+03  5e-02  2e-10  6e-14\n",
      "20: -1.8769e+03 -1.8769e+03  7e-03  2e-11  6e-14\n",
      "21: -1.8769e+03 -1.8769e+03  2e-04  1e-13  6e-14\n",
      "Optimal solution found.\n",
      "Acc: 0.5818921668362157\n",
      "0.6462395543175488\n",
      "0.6178403755868545\n",
      "0.4686346863468635\n",
      "macro-F1: 0.5775715387504222\n",
      "micro-F1: 0.5818921668362157\n"
     ]
    }
   ],
   "source": [
    "#kernel为核函数类型，可能的类型有'Linear'/'Poly'/'Gauss'\n",
    "#C为软间隔参数；\n",
    "#Epsilon为拉格朗日乘子阈值，低于此阈值时将该乘子设置为0\n",
    "kernel='Gauss' \n",
    "C = 1\n",
    "Epsilon=10e-5\n",
    "#生成SVM分类器\n",
    "SVM=SupportVectorMachine(kernel,C,Epsilon)\n",
    "predictions = []\n",
    "#one-vs-all方法训练num_class个二分类器\n",
    "for k in range(1,num_class+1):\n",
    "    #将第k类样本label置为1，其余类别置为-1\n",
    "    train_label=svm_label(Train_label,k)\n",
    "    # 训练模型，并得到测试集上的预测结果\n",
    "    prediction=SVM.fit(train_data,train_label,test_data)\n",
    "    predictions.append(prediction)\n",
    "predictions=np.array(predictions)\n",
    "#one-vs-all, 最终分类结果选择最大score对应的类别\n",
    "pred=np.argmax(predictions,axis=0)+1\n",
    "\n",
    "# 计算准确率Acc及多分类的F1-score\n",
    "print(\"Acc: \"+str(get_acc(test_label,pred)))\n",
    "print(\"macro-F1: \"+str(get_macro_F1(test_label,pred)))\n",
    "print(\"micro-F1: \"+str(get_micro_F1(test_label,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.3453e+03 -1.0113e+04  6e+04  3e+00  2e-12\n",
      " 1: -9.1009e+02 -6.9922e+03  1e+04  5e-01  2e-12\n",
      " 2: -8.3485e+02 -3.6676e+03  4e+03  2e-01  2e-12\n",
      " 3: -8.3788e+02 -2.2054e+03  2e+03  6e-02  2e-12\n",
      " 4: -9.0835e+02 -1.3485e+03  5e+02  2e-02  2e-12\n",
      " 5: -9.4480e+02 -1.2156e+03  3e+02  8e-03  2e-12\n",
      " 6: -9.6805e+02 -1.1397e+03  2e+02  4e-03  2e-12\n",
      " 7: -9.8196e+02 -1.0995e+03  1e+02  2e-03  2e-12\n",
      " 8: -9.9427e+02 -1.0662e+03  8e+01  1e-03  2e-12\n",
      " 9: -1.0006e+03 -1.0516e+03  5e+01  7e-04  2e-12\n",
      "10: -1.0058e+03 -1.0395e+03  3e+01  4e-04  2e-12\n",
      "11: -1.0091e+03 -1.0330e+03  2e+01  2e-04  2e-12\n",
      "12: -1.0130e+03 -1.0253e+03  1e+01  8e-05  2e-12\n",
      "13: -1.0145e+03 -1.0230e+03  9e+00  5e-05  2e-12\n",
      "14: -1.0161e+03 -1.0203e+03  4e+00  1e-05  2e-12\n",
      "15: -1.0170e+03 -1.0190e+03  2e+00  2e-06  2e-12\n",
      "16: -1.0177e+03 -1.0183e+03  6e-01  3e-07  2e-12\n",
      "17: -1.0179e+03 -1.0180e+03  8e-02  5e-08  2e-12\n",
      "18: -1.0180e+03 -1.0180e+03  9e-03  4e-09  2e-12\n",
      "19: -1.0180e+03 -1.0180e+03  1e-04  5e-11  2e-12\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.9682e+03 -1.0603e+04  5e+04  3e+00  4e-12\n",
      " 1: -2.1011e+03 -8.1536e+03  1e+04  4e-01  4e-12\n",
      " 2: -2.1563e+03 -3.6288e+03  2e+03  3e-02  3e-12\n",
      " 3: -2.5255e+03 -2.8971e+03  4e+02  6e-03  4e-12\n",
      " 4: -2.5807e+03 -2.8329e+03  3e+02  3e-03  4e-12\n",
      " 5: -2.6559e+03 -2.7388e+03  9e+01  1e-03  4e-12\n",
      " 6: -2.6757e+03 -2.7154e+03  4e+01  4e-04  4e-12\n",
      " 7: -2.6882e+03 -2.7008e+03  1e+01  1e-04  4e-12\n",
      " 8: -2.6921e+03 -2.6963e+03  4e+00  3e-05  4e-12\n",
      " 9: -2.6934e+03 -2.6948e+03  1e+00  9e-06  4e-12\n",
      "10: -2.6940e+03 -2.6941e+03  1e-01  1e-07  5e-12\n",
      "11: -2.6941e+03 -2.6941e+03  1e-02  1e-08  4e-12\n",
      "12: -2.6941e+03 -2.6941e+03  1e-03  1e-09  4e-12\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.2173e+03 -1.1255e+04  6e+04  4e+00  5e-12\n",
      " 1: -1.4797e+03 -8.5162e+03  1e+04  4e-01  4e-12\n",
      " 2: -1.4684e+03 -3.1823e+03  2e+03  3e-02  3e-12\n",
      " 3: -1.6725e+03 -2.2831e+03  6e+02  1e-02  3e-12\n",
      " 4: -1.7472e+03 -2.1379e+03  4e+02  4e-03  3e-12\n",
      " 5: -1.7940e+03 -2.0200e+03  2e+02  2e-03  3e-12\n",
      " 6: -1.8084e+03 -1.9878e+03  2e+02  1e-03  3e-12\n",
      " 7: -1.8282e+03 -1.9451e+03  1e+02  7e-04  3e-12\n",
      " 8: -1.8358e+03 -1.9288e+03  9e+01  5e-04  3e-12\n",
      " 9: -1.8393e+03 -1.9214e+03  8e+01  4e-04  3e-12\n",
      "10: -1.8486e+03 -1.8987e+03  5e+01  1e-04  4e-12\n",
      "11: -1.8545e+03 -1.8887e+03  3e+01  5e-05  4e-12\n",
      "12: -1.8580e+03 -1.8831e+03  3e+01  3e-05  4e-12\n",
      "13: -1.8601e+03 -1.8795e+03  2e+01  2e-05  4e-12\n",
      "14: -1.8629e+03 -1.8754e+03  1e+01  9e-06  4e-12\n",
      "15: -1.8642e+03 -1.8736e+03  9e+00  6e-06  3e-12\n",
      "16: -1.8667e+03 -1.8702e+03  4e+00  1e-06  4e-12\n",
      "17: -1.8679e+03 -1.8689e+03  1e+00  1e-07  4e-12\n",
      "18: -1.8683e+03 -1.8684e+03  8e-02  7e-09  4e-12\n",
      "19: -1.8683e+03 -1.8683e+03  1e-02  9e-10  4e-12\n",
      "20: -1.8683e+03 -1.8683e+03  4e-04  2e-11  5e-12\n",
      "Optimal solution found.\n",
      "Acc: 0.5778229908443541\n",
      "0.50814332247557\n",
      "0.6062917063870353\n",
      "0.5639344262295083\n",
      "macro-F1: 0.5594564850307046\n",
      "micro-F1: 0.5778229908443541\n"
     ]
    }
   ],
   "source": [
    "#kernel为核函数类型，可能的类型有'Linear'/'Poly'/'Gauss'\n",
    "#C为软间隔参数；\n",
    "#Epsilon为拉格朗日乘子阈值，低于此阈值时将该乘子设置为0\n",
    "kernel='Poly' \n",
    "C = 1\n",
    "Epsilon=10e-5\n",
    "#生成SVM分类器\n",
    "SVM=SupportVectorMachine(kernel,C,Epsilon)\n",
    "predictions = []\n",
    "#one-vs-all方法训练num_class个二分类器\n",
    "for k in range(1,num_class+1):\n",
    "    #将第k类样本label置为1，其余类别置为-1\n",
    "    train_label=svm_label(Train_label,k)\n",
    "    # 训练模型，并得到测试集上的预测结果\n",
    "    prediction=SVM.fit(train_data,train_label,test_data)\n",
    "    predictions.append(prediction)\n",
    "predictions=np.array(predictions)\n",
    "#one-vs-all, 最终分类结果选择最大score对应的类别\n",
    "pred=np.argmax(predictions,axis=0)+1\n",
    "\n",
    "# 计算准确率Acc及多分类的F1-score\n",
    "print(\"Acc: \"+str(get_acc(test_label,pred)))\n",
    "print(\"macro-F1: \"+str(get_macro_F1(test_label,pred)))\n",
    "print(\"micro-F1: \"+str(get_micro_F1(test_label,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
